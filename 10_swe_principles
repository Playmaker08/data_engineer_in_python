3 ways that you can write modular code with Python: packages, classes, and methods.

// Python modularity in the wild (utilize a class & a method from the popular package numpy.)
# import the numpy package
import numpy as np

# create an array class object
arr = np.array([8, 6, 7, 5, 3, 0, 9])

# use the sort method
arr.sort()

# print the sorted array
print(arr)

// Leveraging documentation
# Load the Counter function into our environment
from collections import Counter

# View the documentation for Counter.most_common
help(Counter.most_common)

# Use Counter to find the top 5 most common words
top_5_words = Counter(words).most_common(5)

# Display the top 5 most common words
print(top_5_words)
=> Output: <script.py> output:
    Help on function most_common in module collections:
    
    most_common(self, n=None)
        List the n most common elements and their counts from the most
        common to the least.  If n is None, then list all element counts.
        
        >>> Counter('abracadabra').most_common(3)
        [('a', 5), ('b', 2), ('r', 2)]
    
    [('@DataCamp', 299), ('to', 263), ('the', 251), ('in', 164), ('RT', 158)]

PEP 8 (Python Enhancement Protocol 8): let us know how to format our code be as readable as possible
pycodestyle: check code in multiple files at once => Output the descriptions of the violations along with info to fix the issue

// Using pycodestyle
# Import needed package
import pycodestyle

# Create a StyleGuide instance
style_checker = pycodestyle.StyleGuide()

# Run PEP 8 check on multiple files
result = style_checker.check_files(['nay_pep8.py', 'yay_pep8.py'])

# Print result of PEP 8 style check
print(result.messages)
=> Output: <script.py> output:
    nay_pep8.py:1:1: E265 block comment should start with '# '
    nay_pep8.py:2:6: E225 missing whitespace around operator
    nay_pep8.py:4:2: E131 continuation line unaligned for hanging indent
    nay_pep8.py:5:6: E131 continuation line unaligned for hanging indent
    nay_pep8.py:6:1: E122 continuation line missing indentation or outdented
    nay_pep8.py:7:1: E265 block comment should start with '# '
    nay_pep8.py:8:1: E402 module level import not at top of file
    nay_pep8.py:9:1: E265 block comment should start with '# '
    nay_pep8.py:10:1: E302 expected 2 blank lines, found 0
    nay_pep8.py:10:18: E231 missing whitespace after ','
    nay_pep8.py:11:2: E111 indentation is not a multiple of 4
    nay_pep8.py:12:2: E111 indentation is not a multiple of 4
    nay_pep8.py:14:1: E265 block comment should start with '# '
    nay_pep8.py:15:1: E305 expected 2 blank lines after class or function definition, found 1
    nay_pep8.py:16:11: E111 indentation is not a multiple of 4
    nay_pep8.py:16:11: E117 over-indented
    nay_pep8.py:16:17: E225 missing whitespace around operator
    nay_pep8.py:16:32: E222 multiple spaces after operator
    nay_pep8.py:16:32: E251 unexpected spaces around keyword / parameter equals
    nay_pep8.py:16:38: E231 missing whitespace after ','
    nay_pep8.py:16:44: E221 multiple spaces before operator
    nay_pep8.py:16:44: E251 unexpected spaces around keyword / parameter equals
    nay_pep8.py:16:47: E251 unexpected spaces around keyword / parameter equals
    nay_pep8.py:17:11: E111 indentation is not a multiple of 4
    nay_pep8.py:17:17: E201 whitespace after '('
    nay_pep8.py:17:25: E202 whitespace before ')'
    nay_pep8.py:17:27: W292 no newline at end of file
{'E265': "block comment should start with '# '", 'E131': 'continuation line unaligned for hanging indent', 'E122': 'continuation line missing indentation or outdented', 'E225': 'missing whitespace around operator', 'E402': 'module level import not at top of file', 'E302': 'expected 2 blank lines, found 0', 'E231': "missing whitespace after ','", 'E111': 'indentation is not a multiple of 4', 'E305': 'expected 2 blank lines after class or function definition, found 1', 'E117': 'over-indented', 'E251': 'unexpected spaces around keyword / parameter equals', 'E222': 'multiple spaces after operator', 'E221': 'multiple spaces before operator', 'W292': 'no newline at end of file', 'E201': "whitespace after '('", 'E202': "whitespace before ')'"}

// Conforming to PEP 8 knowing the output of running pycodestyle:
# Assign data to x
x=[8,3,4]

# Print the data
print(   x )

my_script.py:2:2:  E225 missing whitespace around operator
my_script.py:2:7:  E231 missing whitespace after ','
my_script.py:2:9:  E231 missing whitespace after ','
my_script.py:5:7:  E201 whitespace after '('
my_script.py:5:11: E202 whitespace before ')'

Fix: 
# Assign data to x
x = [8, 3, 4]

# Print the data
print(x)

// PEP 8 in documentation
def print_phrase(phrase, polite=True, shout=False):
    if polite:# It's generally polite to say please
        phrase = 'Please ' + phrase

    if shout:  #All caps looks like a written shout
        phrase = phrase.upper() + '!!'

    print(phrase)


#Politely ask for help
print_phrase('help me', polite=True)
 # Shout about a discovery
print_phrase('eureka', shout=True)

my_script.py:2:15: E261 at least two spaces before inline comment
my_script.py:5:16: E262 inline comment should start with '# '
my_script.py:11:1: E265 block comment should start with '# '
my_script.py:13:2: E114 indentation is not a multiple of four (comment)
my_script.py:13:2: E116 unexpected indentation (comment)

Fix: 
def print_phrase(phrase, polite=True, shout=False):
    if polite:  # It's generally polite to say please
        phrase = 'Please ' + phrase

    if shout:  # All caps looks like a written shout
        phrase = phrase.upper() + '!!'

    print(phrase)


# Politely ask for help
print_phrase('help me', polite=True)
# Shout about a discovery
print_phrase('eureka', shout=True)

*** PACKAGES ***
Minimal python package consists of two elements: a directory and python file
What are the minimal requirements to make an import-able python package? A directory with a blank file named __init__.py (the file lets python know that a directory is a package).

// Naming packages
# Import the package with a name that follows PEP 8
import text_analyzer

// Recognizing packages
The structure of your directory tree is printed below. You'll be working in the file my_script.py that you can see in the tree.

recognizing_packages
├── MY_PACKAGE
│   └── __init__.py
├── package
│   └── __init__.py
├── package_py
│   └── __init__
│       └── __init__.py
├── py_package
│   └── __init__.py
├── pyackage
│   └── init.py
└── my_script.py

Use the information from the context to identify the packages in the directory that follow the minimal structure (minimal package requires a directory containing a single file.
The single file contained in the directory for a minimal package should be named __init__.py). Also should have an appropriate name.
# Import local packages
import package
import py_package

# View the help for each package
help(package)
help(py_package)

=> Output: <script.py> output:
    Help on package package:
    
    NAME
        package
    
    PACKAGE CONTENTS
    
    
    FILE
        /tmp/tmpp3_c8oa0/package/__init__.py
    
    
    Help on package py_package:
    
    NAME
        py_package
    
    PACKAGE CONTENTS
    
    
    FILE
        /tmp/tmpp3_c8oa0/py_package/__init__.py

// Adding functionality to your package
In the file counter_utils.py, you will write 2 functions to be a part of your package: plot_counter and sum_counters. The structure of your package can be seen in the tree below. For the coding portions of this exercise, you will be working in the file counter_utils.py.

text_analyzer
├── __init__.py
└── counter_utils.py

Define top_items using plot_counter's inputs.
# Import needed functionality
from collections import Counter

def plot_counter(counter, n_most_common=5):
  # Subset the n_most_common items from the input counter
  top_items = counter.most_common(n_most_common)
  # Plot `top_items`
  plot_counter_most_common(top_items)

Return the correct output from sum_counters.
# Import needed functionality
from collections import Counter

def sum_counters(counters):
  # Sum the inputted counters
  return sum(counters, Counter())

Lines correctly import these functions in __init__.py using relative import syntax:
from .counter_utils import plot_counter, sum_counters

// Using your package's new functionality
The object word_counts is loaded into your environment. It contains a list of Counter objects that contain word counts from a sample of DataCamp tweets.

The structure you've created can be seen in the tree below. You'll be working in my_script.py.

working_dir
├── text_analyzer
│    ├── __init__.py
│    ├── counter_utils.py
└── my_script.py

# Import local package
import text_analyzer

# Sum word_counts using sum_counters from text_analyzer
word_count_totals = text_analyzer.sum_counters(word_counts)

# Plot word_count_totals using plot_counter from text_analyzer
text_analyzer.plot_counter(word_count_totals)

Sharing functional package to colleagues: creating setup.py and requirements.txt (located at the same level as package directory).
pip install -r allows you to install everything listed in a requirements file.

// Writing requirements.txt
requirements = """
matplotlib>=3.0.0
numpy==1.15.4
pandas<=0.22.0
pycodestyle
"""

// Creating setup.py
# Import needed function from setuptools
from setuptools import setup

# Create proper setup to be used by pip
setup(name='text_analyzer',
      version='0.0.1',
      description='Perform and visualize a text analysis.',
      author='username',
      packages=['text_analyzer'])
=> Output: <script.py> output:
    running bdist_rpm
    running egg_info
    creating text_analyzer.egg-info
    writing text_analyzer.egg-info/PKG-INFO
    writing dependency_links to text_analyzer.egg-info/dependency_links.txt
    writing top-level names to text_analyzer.egg-info/top_level.txt
    writing manifest file 'text_analyzer.egg-info/SOURCES.txt'
    reading manifest file 'text_analyzer.egg-info/SOURCES.txt'
    writing manifest file 'text_analyzer.egg-info/SOURCES.txt'
    creating dist
    writing 'dist/text_analyzer.spec'

// Listing requirements in setup.py
# Import needed function from setuptools
from setuptools import setup

# Create proper setup to be used by pip
setup(name='text_analyzer',
      version='0.0.1',
      description='Perform and visualize a text analysis.',
      author='username',
      packages=['text_analyzer'],
      install_requires=['matplotlib>=3.0.0'])

// Writing a class for your package
Below is the structure of where you'll be working (we'll work in document.py).

working_dir
├── text_analyzer
│    ├── __init__.py
│    ├── counter_utils.py
│    ├── document.py
└── my_script.py

# Define Document class
class Document:
    """A class for text analysis
    
    :param text: string of text to be analyzed
    :ivar text: string of text to be analyzed; set by `text` parameter
    """
    # Method to create a new instance of Document
    def __init__(self, text):
        # Store text parameter to the text attribute
        self.text = text

# Import this class in __init__.py using relative import syntax
from .document import Document

// Using your package's class
Below is the document tree that you've built up so far when developing your package. You'll be working in my_script.py.

working_dir
├── text_analyzer
│    ├── __init__.py
│    ├── counter_utils.py
│    ├── document.py
└── my_script.py

# Import custom text_analyzer package
import text_analyzer

# Create an instance of Document with datacamp_tweet
my_document = text_analyzer.Document(text=datacamp_tweet)

# Print the text attribute of the Document instance
print(my_document.text)

Tokenization (text analysis): breaking up a document into individual words (tokens).

// Writing a non-public method
class Document:
  def __init__(self, text):
    self.text = text
    # pre tokenize the document with non-public tokenize method
    self.tokens = self._tokenize()
    # pre tokenize the document with non-public count_words
    self.word_counts = self._count_words()

  def _tokenize(self):
    return tokenize(self.text)
	
  # non-public method to tally document's word counts with Counter
  def _count_words(self):
    return Counter(self.tokens)

// Using your class's functionality
You've now added additional functionality to your Document class's __init__ method that automatically processes text for your users. In this exercise, you'll act as one of those users to see the benefits of your hard work.

The Document class (copied below) has been loaded into your environment (complete with your new updates).

class Document:
  def __init__(self, text):
    self.text = text
    # pre tokenize the document with non-public tokenize method
    self.tokens = self._tokenize()
    # pre tokenize the document with non-public count_words
    self.word_counts = self._count_words()

  def _tokenize(self):
    return tokenize(self.text)

  # non-public method to tally document's word counts with Counter
  def _count_words(self):
    return Counter(self.tokens)

# create a new document instance from datacamp_tweets
datacamp_doc = Document(datacamp_tweets)

# print the first 5 tokens from datacamp_doc
print(datacamp_doc.tokens[:5])

# print the top 5 most used words in datacamp_doc
print(datacamp_doc.word_counts.most_common(5))
=> Output: <script.py> output:
    ['[DataCamp]', 'Introduction', 'to', 'H', 'O']
    [('DataCamp', 322), ('to', 263), ('the', 251), ('in', 163), ('RT', 158)]

DRY (Don't Repeat Yourself) principle: allow us to write modular, readable code
Ways to follow the rule: writing re-usable functions, classes, and packages
Inheritance: Start with parent class and pass on it's functionality to a child class

// Using inheritance to create a class
# Define a SocialMedia class that is a child of the `Document class`
class SocialMedia(Document):
    def __init__(self, text):
        Document.__init__(self, text)

// Adding functionality to a child class
Build features into SocialMedia to specialize it for use with Social Media data.

Note: For reference, the definition of Document can be seen below:
class Document:
    # Initialize a new Document instance
    def __init__(self, text):
        self.text = text
        # Pre tokenize the document with non-public tokenize method
        self.tokens = self._tokenize()
        # Pre tokenize the document with non-public count_words
        self.word_counts = self._count_words()

    def _tokenize(self):
        return tokenize(self.text)

    # Non-public method to tally document's word counts
    def _count_words(self):
        # Use collections.Counter to count the document's tokens
        return Counter(self.tokens)

# Define a SocialMedia class that is a child of the `Document class`
class SocialMedia(Document):
    def __init__(self, text):
        Document.__init__(self, text)
        self.hashtag_counts = self._count_hashtags()
        self.mention_counts = self._count_mentions()
        
    def _count_hashtags(self):
        # Filter attribute so only words starting with '#' remain
        return filter_word_counts(self.word_counts, first_char='#')
    
    def _count_mentions(self):
        # Filter attribute so only words starting with '@' remain
        return filter_word_counts(self.word_counts, first_char='@')

// Using your child class
Thanks to the power of inheritance you were able to create a feature-rich, SocialMedia class based on its parent, Document. Let's see some of these features in action.

Note: Below is the full definition of SocialMedia for reference. Additionally, SocialMedia has been added to __init__.py for ease of use.
class SocialMedia(Document):
    def __init__(self, text):
        Document.__init__(self, text)
        self.hashtag_counts = self._count_hashtags()
        self.mention_counts = self._count_mentions()

    def _count_hashtags(self):
        # Filter attribute so only words starting with '#' remain
        return filter_word_counts(self.word_counts, first_char='#')      

    def _count_mentions(self):
        # Filter attribute so only words starting with '@' remain
        return filter_word_counts(self.word_counts, first_char='@')

# Import custom text_analyzer package
import text_analyzer

# Create a SocialMedia instance with datacamp_tweets
dc_tweets = text_analyzer.SocialMedia(text=datacamp_tweets)

# Print the top five most mentioned users
print(dc_tweets.mention_counts.most_common(5))

# Plot the most used hashtags
text_analyzer.plot_counter(dc_tweets.hashtag_counts)
=> Output: <script.py> output:
    [('@DataCamp', 299), ('@hugobowne', 57), ('@DataScienceFEM', 18), ('@datacamp', 17), ('@nnstats', 11)]

// Exploring with dir and help
# Import needed package
import text_analyzer

# Create instance of document
my_doc = text_analyzer.Document(datacamp_tweets)

# Run help on my_doc's plot method
help(my_doc.plot_counts)

# Plot the word_counts of my_doc
my_doc.plot_counts()
=> Output: <script.py> output:
    Help on method plot_counts in module text_analyzer.document:
    
    plot_counts(attribute='word_counts', n_most_common=5) method of text_analyzer.document.Document instance
        Plot most common elements of a ``collections.Counter`` instance attribute
        
        :param attribute: name of ``Counter`` attribute to use as object to plot
        :param n_most_common: number of elements to plot (using ``Counter.most_common()``)
        :return: None; a plot is shown using matplotlib
        
        >>> doc = Document("duck duck goose is fun when you're the goose")
        >>> doc.plot_counts('word_counts', n_most_common=5)  # same as default call

// Creating a grandchild class
# Define a Tweet class that inherits from SocialMedia
class Tweets(SocialMedia):
    def __init__(self, text):
        # Call parent's __init__ with super()
        super().__init__()
        # Define retweets attribute with non-public method
        self.retweets = self._process_retweets()

    def _process_retweets(self):
        # Filter tweet text to only include retweets
        retweet_text = filter_lines(self.text, first_chars='RT')
        # Return retweet_text as a SocialMedia object
        return SocialMedia(retweet_text)

// Using inherited methods
# Import needed package
import text_analyzer

# Create instance of Tweets
my_tweets = text_analyzer.Tweets(datacamp_tweets)

# Plot the most used hashtags in the tweets
my_tweets.plot_counts('hashtag_counts')

# Plot the most used hashtags in the retweets
my_tweets.retweets.plot_counts('hashtag_counts')

//
